---
title: "Regularized Regression in Caret"
author: "Cory Costello"
date: "January 24, 2018"
output: 
  md_document:
    preserve_yaml: true
    toc: true
    toc_depth: 2
---

This is intended to provide a (very brief) introduction to some key concepts in Machine Learning/Predictive Modeling, and how they work within a regression context. Regularized regression is a nice place for folks with a psych background to start, because its an extension of the familiar regression models we've all come to know and love.

But, before we dive into regularized regression, we should first cover some basic concepts in machine learning.

# The Bias-Variance Tradeoff, Overfitting, and Cross-Validation

## Bias-Variance Tradeoff

This came up briefly last week, but the bias-variance tradeoff is really crucial to everything we'll talk about today. The basic idea is that you can partition error into two components: bias and variance. **Bias** refers to the extent to which a model produces parameter estimates that miss in a particular direction (e.g., consistently over-estimating or consistently under-estimating a parameter value). **Variance** refers to the extent to which a model produces parameter estimates that vary from their central tendency across different datasets. 

There is a tradeoff between bias and variance: all else equal, increasing bias will decrease variance. The basic idea here is that if we have a zero-bias estimator, it will tend to try to fit everything in the data, whereas an estimator biased in some direction won't. This isn't to say that bias is good or bad, just that there are times where we might want to increase bias to decrease variance. As we'll see later, regularization is basically one method for introducing bias (to minimize variance).

## Overfitting 

This is probably familiar to folks in here (and it came up last week), so I won't say much about it here. The basic idea is that any data has signal and noise. Sometimes, something appears to be signal but is actually noise. That is, when our statistical models are searching for the best solution, they sometimes will be fooled into thinking some noise is signal. This is usually called **overfitting**, and it has presented a pretty substantial problem in statistical modeling. As you'll see, one of our goals is to try to avoid overfitting. Also worth noting is that overfitting will tend to produce a model with high variance, because noise will vary from dataset to dataset (basically by definition), and so a model which has fit noise will not do well across different datasets (with different noise).

## Cross-Validation

Cross-validation generally refers to taking a model that you trained on some data and using it in a new dataset. Unlike a replication, the model parameters carry over from the training to the test data (i.e., you don't simply use the same variables and re-estimate the model parameters; you save the model parameters). You can use cross-validation both to train and evaluate a model. A simple example may make this clear.

Let's say we think home size (in square-feet) is the only relevant predictor for house price. So, we have some data on prices of recently sold houses, and estimate a model predicting house price from square-feet:

$$y_{price} = b_0 + b_1*sqaurefeet$$

Let's say we get these parameter values:

$$y_{price} = 100 + 50*sqaurefeet$$

And now we want to cross-validate in a hold-out sample. We wouldn't simply estimate this model again:

$$y_{price} = b_0 + b_1*sqaurefeet$$

We would instead apply this model:

$$y_{price} = 100 + 50*sqaurefeet$$
And evaluate how well it did.

If instead, we